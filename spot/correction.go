package spot

import (
	"dxcluster/bandmap"
	"math"
	"strings"
	"sync"
	"time"

	lev "github.com/agnivade/levenshtein"
)

// CorrectionSettings captures the knobs that govern whether a consensus-based
// call correction should happen. The values ultimately come from config.yaml,
// but the struct is deliberately defined here so the algorithm can be unit-tested
// without importing the config package (which would create a cycle).
type CorrectionSettings struct {
	// Strategy controls how consensus is computed:
	//   - "center": pick a cluster center (median-like) and compare to subject
	//   - "classic": subject vs. alternate comparisons (legacy behavior)
	//   - "majority": most-reported call on-frequency (unique spotters), distance as safety cap only
	Strategy string
	// DebugLog enables per-subject diagnostic logging of decisions.
	DebugLog bool
	// TraceLogger records decision traces asynchronously when DebugLog is true.
	TraceLogger CorrectionTraceLogger
	// Frequency guard to avoid merging nearby strong signals.
	FreqGuardMinSeparationKHz float64
	FreqGuardRunnerUpRatio    float64
	// FrequencyToleranceHz defines how close two spots must be to be considered the same signal.
	FrequencyToleranceHz float64
	// Quality-based anchors (frequency-binned call scores).
	QualityBinHz            int
	QualityGoodThreshold    int
	QualityNewCallIncrement int
	QualityBustedDecrement  int
	// MinConsensusReports is the number of *other* unique spotters that must
	// agree on the same DX call before we consider overriding the subject spot.
	MinConsensusReports int
	// MinAdvantage is the minimum delta (candidate supporters - subject supporters)
	// required before a correction can happen.
	MinAdvantage int
	// MinConfidencePercent enforces that the alternate call must represent at least
	// this percentage of all unique spotters currently reporting that frequency.
	MinConfidencePercent int
	// RecencyWindow bounds how old the supporting spots can be. Anything older
	// than this duration is ignored so stale data never drives a correction.
	RecencyWindow time.Duration
	// MaxEditDistance bounds how different the alternate call can be compared to
	// the subject call. A value of 2 typically allows single-character typos.
	MaxEditDistance int

	// MinSNRCW/MinSNRRTTY/MinSNRVoice let callers ignore corroborators below a
	// minimum signal-to-noise ratio. FT8/FT4 aren't run through call correction.
	MinSNRCW   int
	MinSNRRTTY int
	// MinSNRVoice lets callers ignore low-SNR USB/LSB reports when present.
	MinSNRVoice int

	// DistanceModelCW/DistanceModelRTTY control mode-specific distance behavior.
	// Supported values:
	//   - "plain": rune-based Levenshtein
	//   - "morse": Morse-aware (CW only)
	//   - "baudot": Baudot-aware (RTTY only)
	DistanceModelCW   string
	DistanceModelRTTY string

	// Distance3Extra* tighten consensus requirements when the candidate callsign
	// is at edit distance 3 from the subject. They are additive to the base
	// thresholds above. Set them to zero to disable the stricter bar.
	Distance3ExtraReports    int
	Distance3ExtraAdvantage  int
	Distance3ExtraConfidence int
	// DistanceCache* control memoization of string distance calculations. This
	// lowers CPU when the same candidate set is evaluated repeatedly during
	// bursts. Disable by setting size<=0 or ttl<=0.
	DistanceCacheSize int
	DistanceCacheTTL  time.Duration
	// Spotter reliability weights (0..1). Reporters below MinSpotterReliability are ignored
	// when counting corroborators.
	SpotterReliability    SpotterReliability
	MinSpotterReliability float64
	// Cooldown protects a subject call from being flipped away when it already has
	// recent diverse support on this frequency bin.
	Cooldown *CallCooldown
	// CooldownMinReporters allows adaptive thresholds per band/state when provided.
	CooldownMinReporters int
}

var correctionEligibleModes = map[string]struct{}{
	"CW":   {},
	"RTTY": {},
	"USB":  {},
	"LSB":  {},
}

// CorrectionTrace captures the inputs and outcome of a correction decision for audit/comparison.
type CorrectionTrace struct {
	Timestamp                 time.Time `json:"ts"`
	Strategy                  string    `json:"strategy"`
	FrequencyKHz              float64   `json:"freq_khz"`
	SubjectCall               string    `json:"subject"`
	WinnerCall                string    `json:"winner"`
	Mode                      string    `json:"mode"`
	Source                    string    `json:"source"`
	TotalReporters            int       `json:"total_reporters"`
	SubjectSupport            int       `json:"subject_support"`
	WinnerSupport             int       `json:"winner_support"`
	RunnerUpSupport           int       `json:"runner_up_support"`
	SubjectConfidence         int       `json:"subject_confidence"`
	WinnerConfidence          int       `json:"winner_confidence"`
	Distance                  int       `json:"distance"`
	DistanceModel             string    `json:"distance_model"`
	MaxEditDistance           int       `json:"max_edit_distance"`
	MinReports                int       `json:"min_reports"`
	MinAdvantage              int       `json:"min_advantage"`
	MinConfidence             int       `json:"min_confidence"`
	Distance3ExtraReports     int       `json:"d3_extra_reports"`
	Distance3ExtraAdvantage   int       `json:"d3_extra_advantage"`
	Distance3ExtraConfidence  int       `json:"d3_extra_confidence"`
	FreqGuardMinSeparationKHz float64   `json:"freq_guard_min_separation_khz"`
	FreqGuardRunnerUpRatio    float64   `json:"freq_guard_runner_ratio"`
	Decision                  string    `json:"decision"`
	Reason                    string    `json:"reason,omitempty"`
}

// Purpose: Determine whether a mode is eligible for call correction.
// Key aspects: Limits to CW/RTTY and USB/LSB voice modes to avoid digital-mode conflicts.
// Upstream: call correction pipeline and harmonic detection.
// Downstream: correctionEligibleModes lookup.
// IsCallCorrectionCandidate returns true if the given mode is eligible for
// consensus-based call correction. Only CW/RTTY and USB/LSB voice modes
// are considered because other digital modes already embed their own error correction.
func IsCallCorrectionCandidate(mode string) bool {
	_, ok := correctionEligibleModes[strings.ToUpper(strings.TrimSpace(mode))]
	return ok
}

// frequencyToleranceKHz defines how close two frequencies must be to be considered
// the "same" signal. We only care about agreement on essentially identical frequencies,
// so we allow a half-kilohertz wiggle room to absorb rounding differences between
// data sources.
var frequencyToleranceKHz = 0.5

// distanceCacheEntry stores a computed distance with expiry.
type distanceCacheEntry struct {
	distance int
	expires  time.Time
}

// distanceCache is a size- and TTL-bound memoization map for call distances.
type distanceCache struct {
	mu      sync.Mutex
	entries map[string]distanceCacheEntry
	order   []string // insertion order for eviction
	max     int
	ttl     time.Duration
}

func (dc *distanceCache) configure(max int, ttl time.Duration) {
	// Purpose: Configure cache capacity and TTL for distance memoization.
	// Key aspects: Disables cache when max/ttl are non-positive.
	// Upstream: normalizeCorrectionSettings.
	// Downstream: map allocation and resets.
	dc.mu.Lock()
	defer dc.mu.Unlock()
	if max <= 0 || ttl <= 0 {
		dc.max = 0
		dc.entries = nil
		dc.order = nil
		dc.ttl = 0
		return
	}
	if dc.max != max || dc.ttl != ttl || dc.entries == nil {
		dc.max = max
		dc.ttl = ttl
		dc.entries = make(map[string]distanceCacheEntry, max)
		dc.order = dc.order[:0]
	}
}

func (dc *distanceCache) get(key string, now time.Time) (int, bool) {
	// Purpose: Retrieve a cached distance value.
	// Key aspects: Enforces TTL expiration and returns (value, ok).
	// Upstream: cachedCallDistance.
	// Downstream: map lookup under lock.
	if dc.max <= 0 || dc.ttl <= 0 {
		return 0, false
	}
	dc.mu.Lock()
	defer dc.mu.Unlock()
	entry, ok := dc.entries[key]
	if !ok {
		return 0, false
	}
	if now.After(entry.expires) {
		delete(dc.entries, key)
		return 0, false
	}
	return entry.distance, true
}

func (dc *distanceCache) put(key string, distance int, now time.Time) {
	// Purpose: Store a distance value and manage eviction order.
	// Key aspects: Keeps order slice bounded and evicts when over capacity.
	// Upstream: cachedCallDistance.
	// Downstream: evictOldest and condenseOrderLocked.
	if dc.max <= 0 || dc.ttl <= 0 {
		return
	}
	dc.mu.Lock()
	defer dc.mu.Unlock()
	if dc.entries == nil {
		dc.entries = make(map[string]distanceCacheEntry, dc.max)
	}
	_, exists := dc.entries[key]
	dc.entries[key] = distanceCacheEntry{
		distance: distance,
		expires:  now.Add(dc.ttl),
	}
	// Track insertion order only for new keys so hot keys don't bloat the order slice.
	if !exists {
		dc.order = append(dc.order, key)
		if len(dc.order) > dc.max*2 {
			dc.condenseOrderLocked()
		}
	}
	if len(dc.entries) > dc.max {
		dc.evictOldest()
	}
}

func (dc *distanceCache) evictOldest() {
	// Purpose: Evict oldest cache entries to stay within max.
	// Key aspects: Deletes from entries and trims order slice.
	// Upstream: distanceCache.put.
	// Downstream: map delete and condenseOrderLocked.
	// Drop oldest entries until we're within the max bound.
	for len(dc.entries) > dc.max && len(dc.order) > 0 {
		k := dc.order[0]
		dc.order = dc.order[1:]
		delete(dc.entries, k)
	}
	// Trim runaway order slice if it has grown much larger than the cache.
	if len(dc.order) > dc.max*2 {
		dc.condenseOrderLocked()
	}
}

// Purpose: Rebuild the eviction order to remove duplicates.
// Key aspects: Keeps latest occurrences and trims order size.
// Upstream: distanceCache.put and evictOldest.
// Downstream: map lookups and slice rebuild.
// condenseOrderLocked rebuilds the order slice to contain unique keys in their latest order,
// keeping memory bounded even when the same key is updated frequently.
func (dc *distanceCache) condenseOrderLocked() {
	if len(dc.order) == 0 {
		return
	}
	seen := make(map[string]bool, len(dc.entries))
	tmp := make([]string, 0, len(dc.entries))
	// Walk from newest to oldest, keep first occurrence, then reverse to restore order.
	for i := len(dc.order) - 1; i >= 0; i-- {
		k := dc.order[i]
		if seen[k] {
			continue
		}
		if _, exists := dc.entries[k]; !exists {
			continue
		}
		seen[k] = true
		tmp = append(tmp, k)
	}
	// Reverse tmp into order (oldest to newest).
	for i, j := 0, len(tmp)-1; i < j; i, j = i+1, j-1 {
		tmp[i], tmp[j] = tmp[j], tmp[i]
	}
	dc.order = tmp
}

// Purpose: Set the global frequency tolerance for correction clustering.
// Key aspects: Normalizes non-positive values to default.
// Upstream: main startup configuration.
// Downstream: frequencyToleranceKHz global.
// SetFrequencyToleranceHz updates the frequency similarity window in Hz.
func SetFrequencyToleranceHz(hz float64) {
	if hz <= 0 {
		frequencyToleranceKHz = 0.5
		return
	}
	frequencyToleranceKHz = hz / 1000.0
}

// Purpose: Configure Morse edit distance weights.
// Key aspects: Applies defaults when non-positive and rebuilds cost table.
// Upstream: main startup configuration.
// Downstream: buildRuneCostTable and morse weight globals.
// ConfigureMorseWeights allows callers to tune dot/dash edit costs. Non-positive
// inputs fall back to defaults (ins=1, del=1, sub=2, scale=2).
func ConfigureMorseWeights(insert, delete, sub, scale int) {
	if insert > 0 {
		morseInsertCost = insert
	} else {
		morseInsertCost = 1
	}
	if delete > 0 {
		morseDeleteCost = delete
	} else {
		morseDeleteCost = 1
	}
	if sub > 0 {
		morseSubCost = sub
	} else {
		morseSubCost = 2
	}
	if scale > 0 {
		morseScale = scale
	} else {
		morseScale = 2
	}
	// Rebuild the Morse cost table with the new weights.
	morseRuneIndex, morseCostTable = buildRuneCostTable(morseCodes, morsePatternCost)
}

// Purpose: Configure Baudot edit distance weights for RTTY.
// Key aspects: Applies defaults when non-positive and rebuilds cost table.
// Upstream: main startup configuration.
// Downstream: buildRuneCostTable and baudot weight globals.
// ConfigureBaudotWeights allows callers to tune ITA2 edit costs for RTTY distance.
// Non-positive inputs fall back to defaults (ins=1, del=1, sub=2, scale=2).
func ConfigureBaudotWeights(insert, delete, sub, scale int) {
	if insert > 0 {
		baudotInsertCost = insert
	} else {
		baudotInsertCost = 1
	}
	if delete > 0 {
		baudotDeleteCost = delete
	} else {
		baudotDeleteCost = 1
	}
	if sub > 0 {
		baudotSubCost = sub
	} else {
		baudotSubCost = 2
	}
	if scale > 0 {
		baudotScale = scale
	} else {
		baudotScale = 2
	}
	baudotRuneIndex, baudotCostTable = buildRuneCostTable(baudotCodes, baudotPatternCost)
}

// SuggestCallCorrection analyzes recent spots on the same frequency and determines
// whether there is overwhelming evidence that the subject spot's DX call should
// be corrected. IMPORTANT: This function only suggests a correction. The caller
// (e.g., the main pipeline when call correction is enabled) decides whether to
// apply it and is responsible for updating any caches or deduplication structures.
//
// Parameters:
//   - subject: the spot we are evaluating.
//   - others: a slice of other recent spots (e.g., from a spatial index). Frequencies are in Hz.
//   - settings: consensus thresholds (min reporters, freshness).
//   - now: the time reference used to evaluate recency. Passing it as an argument
//     rather than calling time.Now() simplifies deterministic testing.
//
// Returns:
//   - correctedCall: the most likely callsign if consensus is met.
//   - supporters: how many unique spotters contributed to the correction.
//   - ok: true if a correction is recommended, false otherwise.
//
// Purpose: Suggest a corrected callsign based on nearby corroborators.
// Key aspects: Applies consensus strategy, distance limits, and confidence gates.
// Upstream: main call correction pipeline.
// Downstream: distance calculations, quality anchors, and logging.
func SuggestCallCorrection(subject *Spot, others []bandmap.SpotEntry, settings CorrectionSettings, now time.Time) (correctedCall string, supporters int, correctedConfidence int, subjectConfidence int, totalReporters int, ok bool) {
	if subject == nil {
		return "", 0, 0, 0, 0, false
	}

	cfg := normalizeCorrectionSettings(settings)
	subjectCall := strings.TrimSpace(subject.DXCall)
	if subjectCall == "" {
		return "", 0, 0, 0, 0, false
	}
	subjectReporter := strings.TrimSpace(subject.DECall)

	trace := CorrectionTrace{
		Timestamp:                 now,
		Strategy:                  strings.ToLower(strings.TrimSpace(cfg.Strategy)),
		FrequencyKHz:              subject.Frequency,
		SubjectCall:               strings.ToUpper(subjectCall),
		Mode:                      strings.ToUpper(strings.TrimSpace(subject.Mode)),
		Source:                    strings.ToUpper(strings.TrimSpace(subject.SourceNode)),
		MaxEditDistance:           cfg.MaxEditDistance,
		MinReports:                cfg.MinConsensusReports,
		MinAdvantage:              cfg.MinAdvantage,
		MinConfidence:             cfg.MinConfidencePercent,
		Distance3ExtraReports:     cfg.Distance3ExtraReports,
		Distance3ExtraAdvantage:   cfg.Distance3ExtraAdvantage,
		Distance3ExtraConfidence:  cfg.Distance3ExtraConfidence,
		FreqGuardMinSeparationKHz: cfg.FreqGuardMinSeparationKHz,
		FreqGuardRunnerUpRatio:    cfg.FreqGuardRunnerUpRatio,
		DistanceModel:             distanceModelPlain,
	}
	switch trace.Mode {
	case "CW":
		trace.DistanceModel = normalizeCWDistanceModel(cfg.DistanceModelCW)
	case "RTTY":
		trace.DistanceModel = normalizeRTTYDistanceModel(cfg.DistanceModelRTTY)
	}
	allReporters := map[string]struct{}{}
	clusterSpots := make([]bandmap.SpotEntry, 0, len(others)+1)
	clusterSpots = append(clusterSpots, bandmap.SpotEntry{
		Call:    subject.DXCall,
		Spotter: subject.DECall,
		Mode:    subject.Mode,
		FreqHz:  uint32(subject.Frequency*1000 + 0.5),
		Time:    subject.Time.Unix(),
		SNR:     subject.Report,
	})

	type callAggregate struct {
		reporters map[string]struct{}
		lastSeen  time.Time
		lastFreq  float64
	}

	// Pre-size call stats map to avoid resize churn; expect up to len(others)+1 unique calls.
	callStats := make(map[string]*callAggregate, len(others)+1)
	ensureCallEntry := func(call string) *callAggregate {
		entry, ok := callStats[call]
		if !ok {
			entry = &callAggregate{reporters: make(map[string]struct{}, 4)}
			callStats[call] = entry
		}
		return entry
	}
	addReporter := func(call, reporter string, seenAt time.Time, freqKHz float64) {
		// Ignore reporters that fall below the configured reliability floor.
		if reliabilityFor(cfg.SpotterReliability, reporter) < cfg.MinSpotterReliability {
			return
		}
		entry := ensureCallEntry(call)
		entry.reporters[reporter] = struct{}{}
		if seenAt.After(entry.lastSeen) {
			entry.lastSeen = seenAt
		}
		entry.lastFreq = freqKHz
	}

	subjectAgg := ensureCallEntry(subjectCall)
	if subjectReporter != "" && passesSNRThreshold(subject, cfg) {
		addReporter(subjectCall, subjectReporter, subject.Time, subject.Frequency)
		allReporters[subjectReporter] = struct{}{}
	}
	if subjectAgg.lastSeen.IsZero() {
		subjectAgg.lastSeen = subject.Time
		subjectAgg.lastFreq = subject.Frequency
	}

	toleranceHz := cfg.FrequencyToleranceHz
	if toleranceHz <= 0 {
		toleranceHz = 500 // fallback to a half-kHz window
	}
	toleranceKHz := toleranceHz / 1000.0

	for _, entry := range others {
		otherCall := strings.TrimSpace(entry.Call)
		if otherCall == "" {
			continue
		}
		reporter := strings.TrimSpace(entry.Spotter)
		if reporter == "" {
			continue
		}
		if !passesSNREntry(entry, cfg) {
			continue
		}
		entryFreqKHz := float64(entry.FreqHz) / 1000.0
		if math.Abs(entryFreqKHz-subject.Frequency) > toleranceKHz {
			continue
		}
		seenAt := time.Unix(entry.Time, 0)
		if now.Sub(seenAt) > cfg.RecencyWindow {
			continue
		}
		if reporter == subjectReporter {
			if otherCall == subjectCall {
				allReporters[reporter] = struct{}{}
				addReporter(otherCall, reporter, seenAt, entryFreqKHz)
			}
			continue
		}
		if !strings.EqualFold(entry.Mode, subject.Mode) {
			continue
		}
		allReporters[reporter] = struct{}{}
		addReporter(otherCall, reporter, seenAt, entryFreqKHz)
		clusterSpots = append(clusterSpots, entry)
	}

	totalReporters = len(allReporters)
	trace.TotalReporters = totalReporters
	if totalReporters == 0 {
		trace.Decision = "rejected"
		trace.Reason = "no_reporters"
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, 0, 0, false
	}

	cacheCfg := distanceCacheConfig{
		size: cfg.DistanceCacheSize,
		ttl:  cfg.DistanceCacheTTL,
	}
	localCache := &distanceCache{}
	localCache.configure(cacheCfg.size, cacheCfg.ttl)
	freqHz := subject.Frequency * 1000.0

	if cfg.Cooldown != nil && subjectAgg != nil {
		cfg.Cooldown.Record(subjectCall, freqHz, subjectAgg.reporters, cfg.CooldownMinReporters, cfg.RecencyWindow, now)
	}

	// Majority-of-unique-spotters: pick the call with the most unique reporters
	// on-frequency (within recency/SNR gates). Distance is only a safety cap.
	callKeys := make([]string, len(callStats))
	i := 0
	for call := range callStats {
		callKeys[i] = call
		i++
	}
	if len(callKeys) == 0 {
		return "", 0, 0, 0, 0, false
	}

	subjectCount := len(subjectAgg.reporters)
	trace.SubjectSupport = subjectCount
	if totalReporters > 0 {
		subjectConfidence = subjectCount * 100 / totalReporters
	}
	trace.SubjectConfidence = subjectConfidence

	// Anchor path: use existing good calls in this bin to snap busted calls quickly.
	allCalls := make([]string, 0, len(callKeys)+1)
	allCalls = append(allCalls, subjectCall)
	seen := map[string]struct{}{subjectCall: {}}
	for _, c := range callKeys {
		if _, ok := seen[c]; !ok {
			allCalls = append(allCalls, c)
			seen[c] = struct{}{}
		}
	}
	hasGoodAnchor := false
	for _, c := range allCalls {
		if callQuality.IsGood(c, freqHz, &cfg) {
			hasGoodAnchor = true
			break
		}
	}
	if hasGoodAnchor {
		if anchor, okAnchor := findAnchorForCall(subjectCall, freqHz, subject.Mode, allCalls, &cfg); okAnchor {
			anchorSupport := 0
			if agg := callStats[anchor]; agg != nil {
				anchorSupport = len(agg.reporters)
			}
			anchorConfidence := 0
			if totalReporters > 0 {
				anchorConfidence = anchorSupport * 100 / totalReporters
			}
			anchorDistance := cachedCallDistance(subjectCall, anchor, subject.Mode, cfg.DistanceModelCW, cfg.DistanceModelRTTY, cacheCfg, localCache, now)
			anchorRunner := 0
			for call, agg := range callStats {
				if call == anchor || agg == nil {
					continue
				}
				if len(agg.reporters) > anchorRunner {
					anchorRunner = len(agg.reporters)
				}
			}
			updateCallQualityForCluster(anchor, freqHz, &cfg, clusterSpots)
			trace.WinnerCall = strings.ToUpper(anchor)
			trace.WinnerSupport = anchorSupport
			trace.RunnerUpSupport = anchorRunner
			trace.WinnerConfidence = anchorConfidence
			trace.Distance = anchorDistance
			trace.Decision = "applied"
			logCorrectionTrace(cfg, trace, clusterSpots)
			return anchor, anchorSupport, anchorConfidence, subjectConfidence, totalReporters, true
		}
	}

	bestCall := ""
	bestCount := 0
	bestConfidence := 0
	var bestTime time.Time
	bestFreq := 0.0
	runnerUp := 0
	runnerUpFreq := 0.0
	for _, candidateCall := range callKeys {
		agg := callStats[candidateCall]
		if agg == nil {
			continue
		}
		count := len(agg.reporters)
		confidence := count * 100 / totalReporters
		if count > bestCount || (count == bestCount && agg.lastSeen.After(bestTime)) {
			runnerUp = bestCount
			runnerUpFreq = bestFreq
			bestCall = candidateCall
			bestCount = count
			bestConfidence = confidence
			bestTime = agg.lastSeen
			bestFreq = agg.lastFreq
		}
	}

	if bestCall == "" || bestCall == subjectCall {
		trace.Decision = "rejected"
		trace.Reason = "no_winner"
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, subjectConfidence, totalReporters, false
	}

	centerDistance := cachedCallDistance(subjectCall, bestCall, subject.Mode, cfg.DistanceModelCW, cfg.DistanceModelRTTY, cacheCfg, localCache, now)
	trace.Distance = centerDistance
	trace.WinnerCall = strings.ToUpper(bestCall)
	trace.WinnerSupport = bestCount
	trace.WinnerConfidence = bestConfidence
	trace.RunnerUpSupport = runnerUp

	if cfg.MaxEditDistance >= 0 && centerDistance > cfg.MaxEditDistance {
		trace.Decision = "rejected"
		trace.Reason = "max_edit_distance"
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, subjectConfidence, totalReporters, false
	}

	// Apply consensus thresholds anchored on the majority winner.
	minReports := cfg.MinConsensusReports
	minAdvantage := cfg.MinAdvantage
	minConf := cfg.MinConfidencePercent
	if centerDistance >= 3 {
		minReports += cfg.Distance3ExtraReports
		minAdvantage += cfg.Distance3ExtraAdvantage
		minConf += cfg.Distance3ExtraConfidence
	}
	if bestCount < minReports {
		trace.Decision = "rejected"
		trace.Reason = "min_reports"
		trace.MinReports = minReports
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, subjectConfidence, totalReporters, false
	}
	if bestCount < subjectCount+minAdvantage {
		trace.Decision = "rejected"
		trace.Reason = "advantage"
		trace.MinAdvantage = minAdvantage
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, subjectConfidence, totalReporters, false
	}
	if bestConfidence < minConf {
		trace.Decision = "rejected"
		trace.Reason = "confidence"
		trace.MinConfidence = minConf
		logCorrectionTrace(cfg, trace, clusterSpots)
		return "", 0, 0, subjectConfidence, totalReporters, false
	}

	// Frequency-aware guard: if a nearby runner-up has comparable support, skip correction to avoid merging distinct signals.
	if runnerUp > 0 {
		freqSeparation := math.Abs(bestFreq - runnerUpFreq)
		if freqSeparation >= cfg.FreqGuardMinSeparationKHz && float64(runnerUp) >= cfg.FreqGuardRunnerUpRatio*float64(bestCount) {
			trace.Decision = "rejected"
			trace.Reason = "freq_guard"
			logCorrectionTrace(cfg, trace, clusterSpots)
			return "", 0, 0, subjectConfidence, totalReporters, false
		}
	}

	if cfg.Cooldown != nil {
		if block, _ := cfg.Cooldown.ShouldBlock(subjectCall, freqHz, cfg.CooldownMinReporters, cfg.RecencyWindow, subjectCount, subjectConfidence, bestCount, bestConfidence, now); block {
			trace.Decision = "rejected"
			trace.Reason = "cooldown"
			logCorrectionTrace(cfg, trace, clusterSpots)
			return "", 0, 0, subjectConfidence, totalReporters, false
		}
	}

	updateCallQualityForCluster(bestCall, freqHz, &cfg, clusterSpots)
	trace.Decision = "applied"
	logCorrectionTrace(cfg, trace, clusterSpots)

	return bestCall, bestCount, bestConfidence, subjectConfidence, totalReporters, true
}

// Purpose: Select the closest good anchor call for a busted call.
// Key aspects: Uses mode-aware distance and quality anchors.
// Upstream: SuggestCallCorrection.
// Downstream: callQuality.IsGood and callDistance.
// findAnchorForCall selects the closest good anchor (by mode-aware distance) for a busted call.
func findAnchorForCall(bustedCall string, freqHz float64, mode string, candidates []string, cfg *CorrectionSettings) (string, bool) {
	busted := strings.TrimSpace(bustedCall)
	if busted == "" || cfg == nil {
		return "", false
	}
	modeKey := strings.TrimSpace(mode)
	best := ""
	bestDist := math.MaxInt
	for _, c := range candidates {
		c = strings.TrimSpace(c)
		if c == "" || c == busted {
			continue
		}
		if !callQuality.IsGood(c, freqHz, cfg) {
			continue
		}
		dist := callDistance(busted, c, modeKey, cfg.DistanceModelCW, cfg.DistanceModelRTTY)
		if cfg.MaxEditDistance >= 0 && dist > cfg.MaxEditDistance {
			continue
		}
		if dist < bestDist {
			bestDist = dist
			best = c
		}
	}
	if best == "" {
		return "", false
	}
	return best, true
}

// Purpose: Update call quality scores after a cluster decision.
// Key aspects: Rewards winner and penalizes busted calls.
// Upstream: SuggestCallCorrection.
// Downstream: callQuality.Add.
// updateCallQualityForCluster updates the quality store after a resolved cluster.
func updateCallQualityForCluster(winnerCall string, freqHz float64, cfg *CorrectionSettings, clusterSpots []bandmap.SpotEntry) {
	if cfg == nil || winnerCall == "" || len(clusterSpots) == 0 {
		return
	}
	callQuality.Add(winnerCall, freqHz, cfg.QualityBinHz, cfg.QualityNewCallIncrement)

	distinct := make(map[string]struct{})
	for _, s := range clusterSpots {
		call := strings.TrimSpace(s.Call)
		if call == "" {
			continue
		}
		distinct[call] = struct{}{}
	}
	for call := range distinct {
		if call == strings.ToUpper(strings.TrimSpace(winnerCall)) {
			continue
		}
		callQuality.Add(call, freqHz, cfg.QualityBinHz, -cfg.QualityBustedDecrement)
	}
}

// Purpose: Emit a correction trace to the configured logger.
// Key aspects: No-op when debug logging is disabled.
// Upstream: SuggestCallCorrection.
// Downstream: cfg.TraceLogger.Enqueue.
func logCorrectionTrace(cfg CorrectionSettings, tr CorrectionTrace, votes []bandmap.SpotEntry) {
	if !cfg.DebugLog || cfg.TraceLogger == nil {
		return
	}
	cfg.TraceLogger.Enqueue(CorrectionLogEntry{
		Trace: tr,
		Votes: votes,
	})
}

// Purpose: Normalize correction settings with defaults.
// Key aspects: Applies minimums and standardizes strategy names.
// Upstream: SuggestCallCorrection.
// Downstream: distance cache configuration and string normalization.
// normalizeCorrectionSettings fills in safe defaults so callers can omit config
// while unit tests can deliberately pass tiny values.
func normalizeCorrectionSettings(settings CorrectionSettings) CorrectionSettings {
	cfg := settings
	// Honor configured strategy; fallback to majority when blank/invalid.
	switch strings.ToLower(strings.TrimSpace(cfg.Strategy)) {
	case "center", "classic", "majority":
		cfg.Strategy = strings.ToLower(strings.TrimSpace(cfg.Strategy))
	default:
		cfg.Strategy = "majority"
	}
	if cfg.FreqGuardMinSeparationKHz <= 0 {
		cfg.FreqGuardMinSeparationKHz = 0.1
	}
	if cfg.FreqGuardRunnerUpRatio <= 0 {
		cfg.FreqGuardRunnerUpRatio = 0.5
	}
	if cfg.FrequencyToleranceHz <= 0 {
		cfg.FrequencyToleranceHz = 500
	}
	if cfg.QualityBinHz <= 0 {
		cfg.QualityBinHz = 1000
	}
	if cfg.QualityGoodThreshold <= 0 {
		cfg.QualityGoodThreshold = 2
	}
	if cfg.QualityNewCallIncrement == 0 {
		cfg.QualityNewCallIncrement = 1
	}
	if cfg.QualityBustedDecrement == 0 {
		cfg.QualityBustedDecrement = 1
	}
	if cfg.MinConsensusReports <= 0 {
		cfg.MinConsensusReports = 4
	}
	if cfg.MinAdvantage <= 0 {
		cfg.MinAdvantage = 1
	}
	if cfg.MinConfidencePercent <= 0 {
		cfg.MinConfidencePercent = 70
	}
	if cfg.RecencyWindow <= 0 {
		cfg.RecencyWindow = 45 * time.Second
	}
	if cfg.MaxEditDistance <= 0 {
		cfg.MaxEditDistance = 2
	}
	if cfg.MinSNRCW < 0 {
		cfg.MinSNRCW = 0
	}
	if cfg.MinSNRRTTY < 0 {
		cfg.MinSNRRTTY = 0
	}
	if cfg.Distance3ExtraReports < 0 {
		cfg.Distance3ExtraReports = 0
	}
	if cfg.Distance3ExtraAdvantage < 0 {
		cfg.Distance3ExtraAdvantage = 0
	}
	if cfg.Distance3ExtraConfidence < 0 {
		cfg.Distance3ExtraConfidence = 0
	}
	if cfg.DistanceCacheSize <= 0 {
		cfg.DistanceCacheSize = 5000
	}
	cfg.DistanceModelCW = normalizeCWDistanceModel(cfg.DistanceModelCW)
	cfg.DistanceModelRTTY = normalizeRTTYDistanceModel(cfg.DistanceModelRTTY)
	if cfg.DistanceCacheTTL <= 0 {
		// Default TTL tracks the recency window so cached distances expire alongside supporting data.
		cfg.DistanceCacheTTL = cfg.RecencyWindow
		if cfg.DistanceCacheTTL <= 0 {
			cfg.DistanceCacheTTL = 2 * time.Minute
		}
	}
	if cfg.MinSpotterReliability < 0 {
		cfg.MinSpotterReliability = 0
	}
	return cfg
}

// Purpose: Return the minimum SNR threshold for a mode.
// Key aspects: Uses per-mode thresholds from config.
// Upstream: passesSNRThreshold and passesSNREntry.
// Downstream: strings.ToUpper.
func minSNRThresholdForMode(mode string, cfg CorrectionSettings) int {
	switch strings.ToUpper(strings.TrimSpace(mode)) {
	case "CW":
		return cfg.MinSNRCW
	case "RTTY":
		return cfg.MinSNRRTTY
	case "USB", "LSB":
		return cfg.MinSNRVoice
	default:
		return 0
	}
}

// Purpose: Check whether a spot meets the SNR threshold for its mode.
// Key aspects: Requires HasReport to enforce thresholds.
// Upstream: SuggestCallCorrection.
// Downstream: minSNRThresholdForMode.
func passesSNRThreshold(s *Spot, cfg CorrectionSettings) bool {
	if s == nil {
		return false
	}
	required := minSNRThresholdForMode(s.Mode, cfg)
	if required <= 0 {
		return true
	}
	return s.Report >= required
}

// Purpose: Check whether a bandmap entry meets SNR threshold.
// Key aspects: Uses entry.Mode and entry.SNR.
// Upstream: SuggestCallCorrection.
// Downstream: minSNRThresholdForMode.
func passesSNREntry(e bandmap.SpotEntry, cfg CorrectionSettings) bool {
	required := minSNRThresholdForMode(e.Mode, cfg)
	if required <= 0 {
		return true
	}
	return e.SNR >= required
}

// CorrectionIndex maintains a time-bounded, frequency-bucketed view of recent
// spots so consensus checks can run without scanning the entire ring buffer.
type CorrectionIndex struct {
	mu       sync.Mutex
	buckets  map[int]*correctionBucket
	lastSeen map[int]time.Time

	sweepQuit chan struct{}
}

type correctionBucket struct {
	spots []*Spot
}

// Purpose: Construct an empty correction index.
// Key aspects: Initializes bucket and lastSeen maps.
// Upstream: main startup.
// Downstream: map allocation.
// NewCorrectionIndex constructs an empty index.
func NewCorrectionIndex() *CorrectionIndex {
	return &CorrectionIndex{
		buckets:  make(map[int]*correctionBucket),
		lastSeen: make(map[int]time.Time),
	}
}

// Purpose: Insert a spot into the frequency bucket index.
// Key aspects: Prunes stale entries and tracks lastSeen per bucket.
// Upstream: processOutputSpots call correction path.
// Downstream: bucketKey and pruneAndAppend.
// Add inserts a spot into the appropriate bucket and prunes stale entries.
func (ci *CorrectionIndex) Add(s *Spot, now time.Time, window time.Duration) {
	if ci == nil || s == nil {
		return
	}
	if window <= 0 {
		window = 45 * time.Second
	}

	key := bucketKey(s.Frequency)

	ci.mu.Lock()
	defer ci.mu.Unlock()

	ci.cleanup(now, window)

	bucket := ci.buckets[key]
	if bucket == nil {
		bucket = &correctionBucket{}
		ci.buckets[key] = bucket
	}

	bucket.spots = pruneAndAppend(bucket.spots, s, now, window)
	if len(bucket.spots) == 0 {
		delete(ci.buckets, key)
		delete(ci.lastSeen, key)
	} else {
		ci.lastSeen[key] = now
	}
}

// Purpose: Retrieve nearby spots for call correction.
// Key aspects: Scans adjacent buckets and prunes stale entries.
// Upstream: SuggestCallCorrection.
// Downstream: bucketKey and prune.
// Candidates retrieves nearby spots within the specified +/- window (kHz).
func (ci *CorrectionIndex) Candidates(subject *Spot, now time.Time, window time.Duration, searchKHz float64) []*Spot {
	if ci == nil || subject == nil {
		return nil
	}
	if window <= 0 {
		window = 45 * time.Second
	}
	if searchKHz <= 0 {
		searchKHz = 0.5
	}

	key := bucketKey(subject.Frequency)
	rangeBuckets := int(math.Ceil(searchKHz * 10))
	minKey := key - rangeBuckets
	maxKey := key + rangeBuckets

	ci.mu.Lock()
	defer ci.mu.Unlock()

	var results []*Spot
	for k := minKey; k <= maxKey; k++ {
		bucket := ci.buckets[k]
		if bucket == nil {
			continue
		}
		bucket.spots = prune(bucket.spots, now, window)
		if len(bucket.spots) == 0 {
			// Drop empty buckets to prevent map growth as frequencies churn.
			delete(ci.buckets, k)
			delete(ci.lastSeen, k)
			continue
		}
		ci.lastSeen[k] = now
		results = append(results, bucket.spots...)
	}
	return results
}

// Purpose: Compute the bucket key for a frequency.
// Key aspects: Half-up rounding to 0.1 kHz.
// Upstream: CorrectionIndex.Add and Candidates.
// Downstream: math.Floor.
func bucketKey(freq float64) int {
	// Half-up rounding to 0.1 kHz keeps bucket boundaries stable at .x5 points.
	return int(math.Floor(freq*10 + 0.5))
}

// Purpose: Drop stale spots outside the recency window.
// Key aspects: Returns a compacted slice of active spots.
// Upstream: Candidates.
// Downstream: time comparisons.
func prune(spots []*Spot, now time.Time, window time.Duration) []*Spot {
	if len(spots) == 0 {
		return spots
	}
	cutoff := now.Add(-window)
	dst := spots[:0]
	for _, s := range spots {
		if s == nil {
			continue
		}
		if s.Time.Before(cutoff) {
			continue
		}
		dst = append(dst, s)
	}
	return dst
}

// Purpose: Prune stale spots and append the new spot.
// Key aspects: Reuses prune() to keep slice compact.
// Upstream: CorrectionIndex.Add.
// Downstream: prune.
func pruneAndAppend(spots []*Spot, s *Spot, now time.Time, window time.Duration) []*Spot {
	spots = prune(spots, now, window)
	return append(spots, s)
}

// Purpose: Remove inactive buckets to bound memory.
// Key aspects: Deletes buckets when lastSeen is outside window.
// Upstream: CorrectionIndex.Add and StartCleanup.
// Downstream: map deletes.
// cleanup removes buckets that have been inactive longer than the window to keep
// the map bounded even when frequencies churn across the spectrum.
func (ci *CorrectionIndex) cleanup(now time.Time, window time.Duration) {
	if len(ci.lastSeen) == 0 {
		return
	}
	cutoff := now.Add(-window)
	for key, last := range ci.lastSeen {
		if last.Before(cutoff) {
			delete(ci.lastSeen, key)
			delete(ci.buckets, key)
		}
	}
}

// Purpose: Start a periodic cleanup goroutine for the index.
// Key aspects: Uses ticker and quit channel; guards against double start.
// Upstream: main startup.
// Downstream: cleanup and time.NewTicker.
// StartCleanup launches a periodic sweep to evict inactive buckets even when Candidates/Add
// are not called frequently, keeping memory bounded.
func (ci *CorrectionIndex) StartCleanup(interval, window time.Duration) {
	if ci == nil {
		return
	}
	if interval <= 0 {
		interval = time.Minute
	}
	ci.mu.Lock()
	if ci.sweepQuit != nil {
		ci.mu.Unlock()
		return
	}
	ci.sweepQuit = make(chan struct{})
	ci.mu.Unlock()

	// Purpose: Periodically invoke cleanup until StopCleanup is called.
	// Key aspects: Ticker-driven loop with quit channel.
	// Upstream: StartCleanup.
	// Downstream: cleanup and ticker.Stop.
	go func() {
		ticker := time.NewTicker(interval)
		defer ticker.Stop()
		for {
			select {
			case <-ticker.C:
				ci.mu.Lock()
				ci.cleanup(time.Now(), window)
				ci.mu.Unlock()
			case <-ci.sweepQuit:
				return
			}
		}
	}()
}

// Purpose: Stop the periodic cleanup goroutine.
// Key aspects: Closes quit channel and clears it.
// Upstream: main shutdown.
// Downstream: channel close only.
// StopCleanup stops the periodic cleanup goroutine.
func (ci *CorrectionIndex) StopCleanup() {
	if ci == nil {
		return
	}
	ci.mu.Lock()
	defer ci.mu.Unlock()
	if ci.sweepQuit != nil {
		close(ci.sweepQuit)
		ci.sweepQuit = nil
	}
}

const (
	distanceModelPlain  = "plain"
	distanceModelMorse  = "morse"
	distanceModelBaudot = "baudot"
)

type distanceCacheConfig struct {
	size int
	ttl  time.Duration
}

// Purpose: Normalize CW distance model selection.
// Key aspects: Defaults to plain when unknown.
// Upstream: normalizeCorrectionSettings and cachedCallDistance.
// Downstream: strings.ToLower.
func normalizeCWDistanceModel(model string) string {
	switch strings.ToLower(strings.TrimSpace(model)) {
	case distanceModelMorse:
		return distanceModelMorse
	default:
		return distanceModelPlain
	}
}

// Purpose: Normalize RTTY distance model selection.
// Key aspects: Defaults to plain when unknown.
// Upstream: normalizeCorrectionSettings and cachedCallDistance.
// Downstream: strings.ToLower.
func normalizeRTTYDistanceModel(model string) string {
	switch strings.ToLower(strings.TrimSpace(model)) {
	case distanceModelBaudot:
		return distanceModelBaudot
	default:
		return distanceModelPlain
	}
}

// Purpose: Compute call distance with optional memoization.
// Key aspects: Uses cache when configured, falls back to core distance.
// Upstream: SuggestCallCorrection and findAnchorForCall.
// Downstream: distanceCacheKey, distanceCache.get/put, callDistanceCore.
// cachedCallDistance wraps callDistanceCore with an optional memoization layer.
// A preconfigured cache is supplied by the caller so we avoid reconfiguring
// shared state on every distance call.
func cachedCallDistance(subject, candidate, mode, cwModel, rttyModel string, cacheCfg distanceCacheConfig, cache *distanceCache, now time.Time) int {
	modeKey := strings.ToUpper(strings.TrimSpace(mode))
	cwModelNorm := normalizeCWDistanceModel(cwModel)
	rttyModelNorm := normalizeRTTYDistanceModel(rttyModel)

	if cacheCfg.size > 0 && cacheCfg.ttl > 0 && cache != nil {
		key := distanceCacheKey(subject, candidate, modeKey, cwModelNorm, rttyModelNorm)
		if dist, ok := cache.get(key, now); ok {
			return dist
		}
		dist := callDistanceCore(subject, candidate, modeKey, cwModelNorm, rttyModelNorm)
		cache.put(key, dist, now)
		return dist
	}
	return callDistanceCore(subject, candidate, modeKey, cwModelNorm, rttyModelNorm)
}

// Purpose: Build a stable cache key for distance calculations.
// Key aspects: Concatenates subject/candidate/mode/model identifiers.
// Upstream: cachedCallDistance.
// Downstream: strings.TrimSpace/ToUpper.
func distanceCacheKey(subject, candidate, mode, cwModel, rttyModel string) string {
	var b strings.Builder
	// Estimated capacity: calls (2x12) + 4 delimiters + modes/models (~4*5) + slack.
	b.Grow(48)
	b.WriteString(strings.ToUpper(subject))
	b.WriteByte('|')
	b.WriteString(strings.ToUpper(candidate))
	b.WriteByte('|')
	b.WriteString(mode)
	b.WriteByte('|')
	b.WriteString(cwModel)
	b.WriteByte('|')
	b.WriteString(rttyModel)
	return b.String()
}

// callDistanceCore picks the distance function based on mode/model without caching.
// Purpose: Compute mode-aware call distance without caching.
// Key aspects: Routes to CW/RTTY-specific models or plain Levenshtein.
// Upstream: cachedCallDistance and callDistance.
// Downstream: cwCallDistance, rttyCallDistance, lev.Distance.
func callDistanceCore(subject, candidate, mode, cwModel, rttyModel string) int {
	switch mode {
	case "CW":
		if cwModel == distanceModelMorse {
			return cwCallDistance(subject, candidate)
		}
	case "RTTY":
		if rttyModel == distanceModelBaudot {
			return rttyCallDistance(subject, candidate)
		}
	}
	return lev.ComputeDistance(subject, candidate)
}

// callDistance is retained for tests; it routes to the core distance function
// after normalizing mode/model inputs (no caching).
// Purpose: Compute mode-aware call distance with normalized models.
// Key aspects: Normalizes model strings before calling core.
// Upstream: findAnchorForCall.
// Downstream: callDistanceCore and normalizeCW/RTTYDistanceModel.
func callDistance(subject, candidate, mode, cwModel, rttyModel string) int {
	modeKey := strings.ToUpper(strings.TrimSpace(mode))
	return callDistanceCore(
		subject,
		candidate,
		modeKey,
		normalizeCWDistanceModel(cwModel),
		normalizeRTTYDistanceModel(rttyModel),
	)
}

// Purpose: Compute CW-aware edit distance between two callsigns.
// Key aspects: Uses Levenshtein with Morse-weighted substitutions; insert/delete
// cost 1; pooled DP buffers limit allocations; substitutions use prebuilt costs.
// Upstream: callDistanceCore (CW mode distance path).
// Downstream: morseCharDist, min3, borrowIntSlice, returnIntSlice.
func cwCallDistance(a, b string) int {
	ra := []rune(strings.ToUpper(a))
	rb := []rune(strings.ToUpper(b))
	la := len(ra)
	lb := len(rb)

	if la == 0 {
		return lb
	}
	if lb == 0 {
		return la
	}

	prev, prevPool := borrowIntSlice(lb + 1)
	cur, curPool := borrowIntSlice(lb + 1)
	defer returnIntSlice(prev, prevPool)
	defer returnIntSlice(cur, curPool)

	for j := 0; j <= lb; j++ {
		prev[j] = j // j inserts
	}

	for i := 1; i <= la; i++ {
		cur[0] = i // i deletes
		for j := 1; j <= lb; j++ {
			insert := cur[j-1] + 1
			delete := prev[j] + 1
			replace := prev[j-1] + morseCharDist(ra[i-1], rb[j-1])
			cur[j] = min3(insert, delete, replace)
		}
		prev, cur = cur, prev
	}

	return prev[lb]
}

// Purpose: Return substitution cost between two runes using Morse code weights.
// Key aspects: Looks up precomputed table; falls back to a fixed penalty.
// Upstream: cwCallDistance.
// Downstream: morseRuneIndex, morseCostTable.
func morseCharDist(a, b rune) int {
	if a == b {
		return 0
	}
	if i, ok := morseRuneIndex[a]; ok {
		if j, ok := morseRuneIndex[b]; ok {
			return morseCostTable[i][j]
		}
	}
	// Fallback cost when the rune is not in the Morse table.
	return 2
}

// Purpose: Compute RTTY-aware edit distance between two callsigns.
// Key aspects: Same DP structure as CW but uses Baudot substitution costs.
// Upstream: callDistanceCore (RTTY mode distance path).
// Downstream: baudotCharDist, min3, borrowIntSlice, returnIntSlice.
func rttyCallDistance(a, b string) int {
	ra := []rune(strings.ToUpper(a))
	rb := []rune(strings.ToUpper(b))
	la := len(ra)
	lb := len(rb)

	if la == 0 {
		return lb
	}
	if lb == 0 {
		return la
	}

	prev, prevPool := borrowIntSlice(lb + 1)
	cur, curPool := borrowIntSlice(lb + 1)
	defer returnIntSlice(prev, prevPool)
	defer returnIntSlice(cur, curPool)

	for j := 0; j <= lb; j++ {
		prev[j] = j
	}

	for i := 1; i <= la; i++ {
		cur[0] = i
		for j := 1; j <= lb; j++ {
			insert := cur[j-1] + 1
			delete := prev[j] + 1
			replace := prev[j-1] + baudotCharDist(ra[i-1], rb[j-1])
			cur[j] = min3(insert, delete, replace)
		}
		prev, cur = cur, prev
	}

	return prev[lb]
}

// Purpose: Return substitution cost between two runes using Baudot weights.
// Key aspects: Looks up precomputed table; falls back to a fixed penalty.
// Upstream: rttyCallDistance.
// Downstream: baudotRuneIndex, baudotCostTable.
func baudotCharDist(a, b rune) int {
	if a == b {
		return 0
	}
	if i, ok := baudotRuneIndex[a]; ok {
		if j, ok := baudotRuneIndex[b]; ok {
			return baudotCostTable[i][j]
		}
	}
	// Fallback cost when the rune is not in the Baudot table.
	return 2
}

// Purpose: Return the minimum of three integers.
// Key aspects: Branches to avoid allocations or slices.
// Upstream: cwCallDistance, rttyCallDistance, morsePatternCost, baudotPatternCost.
// Downstream: None.
func min3(a, b, c int) int {
	if a < b {
		if a < c {
			return a
		}
		return c
	}
	if b < c {
		return b
	}
	return c
}

// Purpose: Provide an int buffer for edit-distance DP with optional pooling.
// Key aspects: Reuses a pooled 64-cap slice for small buffers; returns a flag to
// drive proper pool return.
// Upstream: cwCallDistance, rttyCallDistance.
// Downstream: levBufPool.
func borrowIntSlice(n int) ([]int, bool) {
	if n <= 0 {
		return nil, false
	}
	if n <= 64 {
		buf := levBufPool.Get().([]int)
		return buf[:n], true
	}
	return make([]int, n), false
}

// Purpose: Return a pooled DP buffer to the pool.
// Key aspects: Re-slices to the original pool cap to keep buffers bounded.
// Upstream: cwCallDistance, rttyCallDistance.
// Downstream: levBufPool.
func returnIntSlice(buf []int, fromPool bool) {
	if !fromPool || buf == nil {
		return
	}
	// Keep pooled buffers bounded to the original cap.
	if cap(buf) >= 64 {
		levBufPool.Put(buf[:64])
	}
}

var morseCodes = map[rune]string{
	'A': ".-",
	'B': "-...",
	'C': "-.-.",
	'D': "-..",
	'E': ".",
	'F': "..-.",
	'G': "--.",
	'H': "....",
	'I': "..",
	'J': ".---",
	'K': "-.-",
	'L': ".-..",
	'M': "--",
	'N': "-.",
	'O': "---",
	'P': ".--.",
	'Q': "--.-",
	'R': ".-.",
	'S': "...",
	'T': "-",
	'U': "..-",
	'V': "...-",
	'W': ".--",
	'X': "-..-",
	'Y': "-.--",
	'Z': "--..",
	'0': "-----",
	'1': ".----",
	'2': "..---",
	'3': "...--",
	'4': "....-",
	'5': ".....",
	'6': "-....",
	'7': "--...",
	'8': "---..",
	'9': "----.",
	'/': "-..-.",
}

var (
	morseRuneIndex map[rune]int
	morseCostTable [][]int

	morseInsertCost = 1
	morseDeleteCost = 1
	morseSubCost    = 2
	morseScale      = 2

	baudotInsertCost = 1
	baudotDeleteCost = 1
	baudotSubCost    = 2
	baudotScale      = 2

	levBufPool = sync.Pool{
		New: func() interface{} {
			// Typical callsigns are short; a small buffer covers common cases.
			return make([]int, 64)
		},
	}
)

var baudotCodes = map[rune]string{
	'A': "L00011",
	'B': "L11001",
	'C': "L01110",
	'D': "L01001",
	'E': "L00001",
	'F': "L01101",
	'G': "L11010",
	'H': "L10100",
	'I': "L00110",
	'J': "L01011",
	'K': "L01111",
	'L': "L10010",
	'M': "L11100",
	'N': "L01100",
	'O': "L11000",
	'P': "L10110",
	'Q': "L10111",
	'R': "L01010",
	'S': "L00101",
	'T': "L10000",
	'U': "L00111",
	'V': "L11110",
	'W': "L10011",
	'X': "L11101",
	'Y': "L10101",
	'Z': "L10001",
	'0': "F10110",
	'1': "F10111",
	'2': "F10011",
	'3': "F00001",
	'4': "F01010",
	'5': "F10000",
	'6': "F10101",
	'7': "F00111",
	'8': "F00110",
	'9': "F11000",
	'/': "F11101",
}

var (
	baudotRuneIndex map[rune]int
	baudotCostTable [][]int
)

// Purpose: Build Morse and Baudot cost tables at package init.
// Key aspects: Precomputes rune indexes and dense cost matrices for fast lookup.
// Upstream: Go runtime init for the spot package.
// Downstream: buildRuneCostTable, morsePatternCost, baudotPatternCost.
func init() {
	morseRuneIndex, morseCostTable = buildRuneCostTable(morseCodes, morsePatternCost)
	baudotRuneIndex, baudotCostTable = buildRuneCostTable(baudotCodes, baudotPatternCost)
}

// Purpose: Build rune indexes and dense substitution-cost tables for a codebook.
// Key aspects: Computes pairwise costs once; small tables avoid per-call DP.
// Upstream: init.
// Downstream: cost function (morsePatternCost or baudotPatternCost).
func buildRuneCostTable(codebook map[rune]string, cost func(a, b string) int) (map[rune]int, [][]int) {
	index := make(map[rune]int, len(codebook))
	keys := make([]rune, 0, len(codebook))
	for r := range codebook {
		index[r] = len(keys)
		keys = append(keys, r)
	}
	size := len(keys)
	table := make([][]int, size)
	for i := range table {
		table[i] = make([]int, size)
	}
	for i, ra := range keys {
		for j, rb := range keys {
			if ra == rb {
				table[i][j] = 0
				continue
			}
			a := codebook[ra]
			b := codebook[rb]
			table[i][j] = cost(a, b)
		}
	}
	return index, table
}

// Purpose: Compute weighted, normalized edit cost between two Morse patterns.
// Key aspects: Runs Levenshtein on dot/dash strings with weights, then normalizes
// by length and scales to a small integer for substitution costs.
// Upstream: buildRuneCostTable (Morse table build).
// Downstream: getMorseWeights, min3.
func morsePatternCost(a, b string) int {
	cfg := getMorseWeights()
	if a == b {
		return 0
	}
	ra := []rune(a)
	rb := []rune(b)
	la := len(ra)
	lb := len(rb)
	if la == 0 {
		return cfg.ins
	}
	if lb == 0 {
		return cfg.ins
	}
	prev := make([]int, lb+1)
	cur := make([]int, lb+1)

	for j := 0; j <= lb; j++ {
		prev[j] = j * cfg.ins // j inserts
	}

	for i := 1; i <= la; i++ {
		cur[0] = i * cfg.del // i deletes
		for j := 1; j <= lb; j++ {
			subCost := 0
			if ra[i-1] != rb[j-1] {
				subCost = cfg.sub // dot<->dash heavier than insert/delete
			}
			insert := cur[j-1] + cfg.ins
			delete := prev[j] + cfg.del
			replace := prev[j-1] + subCost
			cur[j] = min3(insert, delete, replace)
		}
		prev, cur = cur, prev
	}

	raw := prev[lb]
	maxLen := la
	if lb > maxLen {
		maxLen = lb
	}
	normalized := float64(raw) / float64(maxLen+1)
	scale := cfg.scale
	if scale <= 0 {
		scale = 2
	}
	scaled := int(math.Ceil(normalized * float64(scale)))
	if scaled < 1 && raw > 0 {
		scaled = 1
	}
	return scaled
}

type morseWeightSet struct {
	ins   int
	del   int
	sub   int
	scale int
}

// Purpose: Snapshot the current Morse weighting settings.
// Key aspects: Reads global cost parameters once per call.
// Upstream: morsePatternCost.
// Downstream: None.
func getMorseWeights() morseWeightSet {
	return morseWeightSet{
		ins:   morseInsertCost,
		del:   morseDeleteCost,
		sub:   morseSubCost,
		scale: morseScale,
	}
}

// Purpose: Compute weighted, normalized edit cost between two Baudot patterns.
// Key aspects: Runs weighted Levenshtein and scales the result for substitutions.
// Upstream: buildRuneCostTable (Baudot table build).
// Downstream: min3.
func baudotPatternCost(a, b string) int {
	if a == b {
		return 0
	}
	ra := []rune(a)
	rb := []rune(b)
	la := len(ra)
	lb := len(rb)
	if la == 0 {
		return baudotInsertCost
	}
	if lb == 0 {
		return baudotInsertCost
	}
	prev := make([]int, lb+1)
	cur := make([]int, lb+1)

	for j := 0; j <= lb; j++ {
		prev[j] = j * baudotInsertCost
	}

	for i := 1; i <= la; i++ {
		cur[0] = i * baudotDeleteCost
		for j := 1; j <= lb; j++ {
			subCost := 0
			if ra[i-1] != rb[j-1] {
				subCost = baudotSubCost
			}
			insert := cur[j-1] + baudotInsertCost
			delete := prev[j] + baudotDeleteCost
			replace := prev[j-1] + subCost
			cur[j] = min3(insert, delete, replace)
		}
		prev, cur = cur, prev
	}

	raw := prev[lb]
	maxLen := la
	if lb > maxLen {
		maxLen = lb
	}
	scale := baudotScale
	if scale <= 0 {
		scale = 2
	}
	normalized := float64(raw) / float64(maxLen+1)
	scaled := int(math.Ceil(normalized * float64(scale)))
	if scaled < 1 && raw > 0 {
		scaled = 1
	}
	return scaled
}
